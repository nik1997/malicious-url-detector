{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_md_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWjOUj3MAB8V",
        "colab_type": "code",
        "outputId": "ef54700c-9c6d-4669-aa98-5db20f683859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import sys, os\n",
        "import os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import re\n",
        "\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def getTokens(input):\n",
        "\n",
        "\n",
        "\ttokens = re.split(\"[, \\-?:./]+\",input)\n",
        "\ttokens = list(set(tokens))\n",
        "\n",
        "\tif 'com' in tokens:\n",
        "\t\t# Delete com as most url have it\n",
        "\t\ttokens.remove('com')\n",
        "\n",
        "\treturn tokens\n",
        "\n",
        "\n",
        "allurls = 'https://github.com/faizann24/Using-machine-learning-to-detect-malicious-URLs/raw/master/data/data.csv'\t#path to our all urls file\n",
        "allurlscsv = pd.read_csv(allurls,',',error_bad_lines=False)\t#reading file\n",
        "allurlsdata = pd.DataFrame(allurlscsv)\t#converting to a dataframe\n",
        "\n",
        "allurlsdata = np.array(allurlsdata)\t#converting it into an array\n",
        "random.shuffle(allurlsdata)\t#shuffling\n",
        "\n",
        "y = [d[1] for d in allurlsdata]\t#all labels \n",
        "corpus = [d[0] for d in allurlsdata]\t#all urls corresponding to a label (either good or bad)\n",
        "vectorizer = TfidfVectorizer(tokenizer=getTokens)\t#get a vector for each url but use our customized tokenizer\n",
        "X = vectorizer.fit_transform(corpus)\t#get the X vector\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\t#split into training and testing set 80/20 ratio\n",
        "\n",
        "lgs = LogisticRegression()\t#using logistic regression\n",
        "lgs.fit(X_train, y_train)\n",
        "print(lgs.score(X_test, y_test))\t#pring the score. It comes out to be 98%\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9832566325377855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ofSN3YpBNnn",
        "colab_type": "code",
        "outputId": "2cfe8831-8c1d-4cbd-927a-72a4771d0bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_predict = ['wikipedia.com','google.com/search=faizanahad','pakistanifacebookforever.com/getpassword.php/','www.radsport-voggel.de/wp-admin/includes/log.exe','ahrenhei.without-transfer.ru/nethost.exe','www.itidea.it/centroesteticosothys/img/_notes/gum.exe']\n",
        "\n",
        "X_predict_transformed = vectorizer.transform(X_predict)\n",
        "\n",
        "y_Predict = lgs.predict(X_predict_transformed)\n",
        "\n",
        "for i in range(len(X_predict)):\n",
        "    print(X_predict[i], ':', y_Predict[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wikipedia.com : good\n",
            "google.com/search=faizanahad : bad\n",
            "pakistanifacebookforever.com/getpassword.php/ : bad\n",
            "www.radsport-voggel.de/wp-admin/includes/log.exe : bad\n",
            "ahrenhei.without-transfer.ru/nethost.exe : bad\n",
            "www.itidea.it/centroesteticosothys/img/_notes/gum.exe : bad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1UjIH5bFzSk",
        "colab_type": "code",
        "outputId": "660b21e4-581a-4698-fbdc-06185c6190f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# %tensorflow_version 1.x\n",
        "# trainign neural network\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import json\n",
        "import numpy as np\n",
        "from keras.models import load_model "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO6qIGFvBOHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_converted = np.array([[1, 0] if label=='good' else [0, 1] for label in y])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_converted, test_size=0.95, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b_tx4sTAavP",
        "colab_type": "code",
        "outputId": "cb0b036a-f6f9-4e04-e750-52151683fad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "token_length = len(vectorizer.get_feature_names())\n",
        "token_length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "240794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL6M74MxWbhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2c4a1cf-e5a3-4bf9-95f0-8463a9a1e0fd"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21023, 240794)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hicvnUSJ-Dwy",
        "colab_type": "code",
        "outputId": "c19eb17a-00eb-47f1-d76b-2d68a37d91dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Logistic regression model with only one layera and two output point.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(2, activation='softmax', input_shape=(token_length,)))\n",
        "adam = keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=1,\n",
        "          batch_size=128)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " 3712/21023 [====>.........................] - ETA: 23s - loss: 0.6217 - acc: 0.6840"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLiQjJdsD8TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJoTTuxEAtG",
        "colab_type": "code",
        "outputId": "927bf258-0bff-4297-a9ff-1f884fdfed46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "my_model = load_model('my_model.h5')\n",
        "score = my_model.evaluate(X_test[:10000], y_test[:10000], batch_size=128)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-score[1]*100))\n",
        "# my_model.predict(X_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 12s 1ms/step\n",
            "Baseline Error: 10.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXlC7f2WEwpj",
        "colab_type": "code",
        "outputId": "0b4e2e1b-ee75-48a6-8315-ee5ca4f4364b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_predict = ['wikipedia.com','google.com/search=faizanahad','pakistanifacebookforever.com/getpassword.php/','www.radsport-voggel.de/wp-admin/includes/log.exe','ahrenhei.without-transfer.ru/nethost.exe','www.itidea.it/centroesteticosothys/img/_notes/gum.exe']\n",
        "\n",
        "X_predict_transformed = vectorizer.transform(X_predict)\n",
        "\n",
        "y_Predict = my_model.predict(X_predict_transformed)\n",
        "\n",
        "for i in range(len(X_predict)):\n",
        "    # (1,0) = good and (0, 1) = bad\n",
        "    if y_Predict[i][0] > y_Predict[i][1]:\n",
        "        result = 'good'\n",
        "    else:\n",
        "        result = 'bad'\n",
        "    print(X_predict[i], ':', result)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wikipedia.com : good\n",
            "google.com/search=faizanahad : bad\n",
            "pakistanifacebookforever.com/getpassword.php/ : bad\n",
            "www.radsport-voggel.de/wp-admin/includes/log.exe : bad\n",
            "ahrenhei.without-transfer.ru/nethost.exe : bad\n",
            "www.itidea.it/centroesteticosothys/img/_notes/gum.exe : bad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IDVzSZWMScw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting keras model for tensorflow js\n",
        "!tensorflowjs_converter --input_format keras my_model.h5 model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQGVO3xnNKI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_tokens_count_in_docs = np.zeros(token_length)\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "    arr = X[i].toarray().flatten()\n",
        "    idx_arr = np.where(arr>0)[0]\n",
        "    for idx in idx_arr:\n",
        "        arr_tokens_count_in_docs[idx] += 1\n",
        "\n",
        "    if i % 20000:\n",
        "        print(i, ' rows compiled!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uieg7NVHN6OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_doc_count_dict = {}\n",
        "tokens_list = vectorizer.get_feature_names()\n",
        "tokens_index = {}\n",
        "for i in range(len(tokens_list)):\n",
        "    tokens_doc_count_dict[tokens_list[i]] = arr_tokens_count_in_docs[i]\n",
        "    tokens_index[tokens_list[i]] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5nG6Q2SNUqx",
        "colab_type": "code",
        "outputId": "24c169f4-0bb3-4d80-d59d-ac5093d6fada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "\n",
        "tokens_info = {\n",
        "    'tokens': tokens_list,\n",
        "    'counts': tokens_doc_count_dict,\n",
        "    'indexes': tokens_index\n",
        "}\n",
        "with open('model/tokenInfo.json', 'w') as outfile:\n",
        "    json.dump(tokens_info, outfile)\n",
        "\n",
        "print('Json file compiled!')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Json file compiled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGGgLpbNNiDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip model.zip model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q27c897cNiOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2cfc1b1b-92c7-4fe8-fdf6-7ed82f588d83"
      },
      "source": [
        "!zip -r /content/model.zip /content/model/"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/model/ (stored 0%)\n",
            "  adding: content/model/tokenInfo.json (deflated 66%)\n",
            "  adding: content/model/group1-shard1of1.bin (deflated 7%)\n",
            "  adding: content/model/model.json (deflated 56%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvJJ8UqCNiYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXdjEdpJNijc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQJKGxut_zJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('logistic-regression')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSzTleaeNgkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUfbiKMpO-gR",
        "colab_type": "code",
        "outputId": "e41d3e74-abf2-4d86-ac19-e5c78fb3e7d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "import tensorflowjs as tfjs\n",
        "tfjs.converters.save_keras_model(my_model, \"tf_model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-6b70d81c1c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tf_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflowjs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconverters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflowjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_tfjs_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflowjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_tfjs_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_keras_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflowjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_saved_model_conversion_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_tf_saved_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# enable eager execution for v2 APIs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m CLEARED_TENSOR_FIELDS = (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5717\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5718\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5719\u001b[0;31m         server_def=None)\n\u001b[0m\u001b[1;32m   5720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   5776\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5777\u001b[0m       raise ValueError(\n\u001b[0;32m-> 5778\u001b[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5779\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5780\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GoeenSFi91H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_tokens = len(vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stHiJRMNjcOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_doc_count = np.zeros(len(vectorizer.get_feature_names()))\n",
        "# tokens_doc_count = {}\n",
        "# for name in vectorizer.get_feature_names():\n",
        "#     tokens_doc_count[name] = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J8Dx6l_kHgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTyjDJLQkMQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(X.shape[0]):\n",
        "    arr = X[i].toarray().flatten()\n",
        "    idx_arr = np.where(arr>0)[0]\n",
        "    for idx in idx_arr:\n",
        "        tokens_doc_count[idx] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8vL3dHolZjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_doc_count_dict = {}\n",
        "tokens_list = vectorizer.get_feature_names()\n",
        "tokens_index = {}\n",
        "for i in range(len(tokens_list)):\n",
        "    tokens_doc_count_dict[tokens_list[i]] = tokens_doc_count[i]\n",
        "    tokens_index[tokens_list[i]] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaSI-cmxlcEj",
        "colab_type": "code",
        "outputId": "9df9ce3a-5777-40ad-8fef-7a8fa9d45ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokens_doc_count_dict['biz']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1075.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG9ZcvH_1A1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('tokenCount.json', 'w') as outfile:\n",
        "    json.dump(tokens_doc_count_dict, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4h4naJvljjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "tokens_info = {\n",
        "    'tokens': tokens_list,\n",
        "    'counts': tokens_doc_count_dict,\n",
        "    'indexes': tokens_index\n",
        "}\n",
        "with open('tokenInfo.json', 'w') as outfile:\n",
        "    json.dump(tokens_info, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30bRGvS-lpcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_list_js = f'const tokens = {tokens_list};' \n",
        "token_counts_js = f'const tokenCounts = {tokens_doc_count_dict};'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsocDLaSltrp",
        "colab_type": "code",
        "outputId": "5d12dcc4-2bee-4c09-ee4f-760543b40a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('token_list.js', 'w') as outfile:\n",
        "    outfile.write(token_list_js)\n",
        "\n",
        "with open('token_counts.js', 'w') as outfile:\n",
        "    outfile.write(token_counts_js)\n",
        "print('File write complete')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File write complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMBzJYXFtVPd",
        "colab_type": "code",
        "outputId": "3c102a1a-8dfb-4c00-f66d-bee40eb88494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('tokens.js', 'w') as outfile:\n",
        "    outfile.write(js_script)\n",
        "\n",
        "print('File write complete')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File write complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt3NKSivuU44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"demofile3.txt\", \"w\")\n",
        "f.write(js_script)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbDOFEwwuZM5",
        "colab_type": "code",
        "outputId": "57078e1f-58d5-4685-8614-146924d75b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test[0].toarray().shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 394817)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTPkXlcp4Pzt",
        "colab_type": "code",
        "outputId": "3e2a7686-c862-47f9-f9f2-6ffbc15197c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "my_model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAsHJn-SCjak",
        "colab_type": "code",
        "outputId": "7b300096-198b-49f0-805f-7944f523f059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "my_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-bb3dd21b7aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (394288,) but got array with shape (394817,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCkUFcC_C6Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}